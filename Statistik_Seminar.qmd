---
title: "Statistik für die Angewandte Forschung"
format: pptx
author: "Dr. Tom Alby"
---

# Sitzung 1: Einführung & Organisatorisches

## Ziele dieser Veranstaltung

-   Werkzeuge für Datenanalyse in der Bachelor-Arbeit
-   Grundkenntnisse Statistik, nicht nur für die Uni

## Was Sie erwartet

-   Einführung in R und RStudio
-   Datenimport und -aufbereitung
-   Explorative Datenanalyse
-   Datenvisualisierung
-   Wahrscheinlichkeitsrechnung
-   Lineare Regression
-   Hypothesentests
-   Korrelationen

## Erwartungen und Interaktion

-   **Slido:** Interaktive Beteiligung über [Slido](https://app.sli.do)
    -   16 Uhr: #68430031
    -   18 Uhr: #68430032

## Welche Note kann ich erwarten?

![](images/grade-distribution.png)

## Rules of Working

-   **Fragen:** Bitte unterbrechen Sie mich für Fragen
-   **Kontakt:** [tom\@alby.de](mailto:tom@alby.de)
-   **Moodle:** Einschreibeschlüssel: iLoveStats!
-   **Materialien:** <https://alby.link/statistik>
-   **Teilnahme:** Präsenzpflicht, in Ausnahmefällen auch online via Zoom (HU), Aufzeichnungen verfügbar

## Prüfungsleistung

-   **Prüfungsleistung:** Hausarbeit mit einer Bearbeitungszeit von sechs Wochen
-   **Keine Gruppenarbeit:** Im Kurs ja, für die Hausarbeit nein
-   **ChatGPT & Co:** Erlaubt, aber...
-   Bitte kein **bedeutungsloser Wohlklang**

## Wie sieht die Hausarbeit aus?

-   **Sie** suchen sich einen Datensatz aus und **holen** sich das **Ok**
-   Hausarbeit in einem speziellen **Dateiformat**, das im Kurs vermittelt wird
-   Hausarbeit wird **während des Semesters** vorbereitet
-   Wöchentliche Besprechung im Seminar
-   Möglichkeit der **Probeabgabe**
-   **Bewertungskriterien** sind online

## Letzte Fragen?

## Unterstützung für Studierende

-   Studentische Seelsorge, rund um die Uhr: 040 41170411
-   [Studierendenberatung\@haw-hamburg.de](mailto:Studierendenberatung@haw-hamburg.de)
-   [krisenteam\@haw-hamburg.de](mailto:krisenteam@haw-hamburg.de)
-   Psychologische Sprechzeit ohne Anmeldung (Dienstags 14-15 Uhr): +49 152 247 44 063
-   Weitere Infos: [HAW Beratung](https://www.haw-hamburg.de/beratung/)

## Let's start!

![](images/marketoonist-big-data.png)

## Was sind Daten?

## Was sind Daten?

-   *Daten*
    -   Roh, ungeordnet, noch nicht interpretiert
    -   Bestehen aus Zahlen, Zeichen, Fakten ohne Kontext
-   *Informationen*
    -   Verarbeitete, kontextualisierte Daten
    -   Haben Bedeutung und Relevanz für eine Fragestellung
    -   **Daten + Kontext = Information**

## DIKW-Pyramide

![](images/dikw-pyramid-removebg-preview.png)

## Toms Pyramide

![](images/tattoo.png)

## Daten oder Informationen?

![](images/daten-oder-informationen.png)

## Skalenniveau

| Statistische Einheit / Merkmalsträger | Merkmal | Ausprägung | Typ / Skala | Erläuterung |
|---------------|---------------|---------------|---------------|---------------|
| n1 | Haarfarbe | Rot | Kategorial / nominalskaliert | Keine Abstände |
| n1 | Postleitzahl | 22703 | Numerisch / nominalskaliert | Keine Abstände |
| n1 | Schulabschluss | Abitur | Kategorial / ordinalskaliert | willkürliche Abstände |
| Sport-Team A | Tabellenplatz | 7 | Numerisch / ordinalskaliert | willkürliche Abstände |
| n1 | Körpertemperatur | 36,5°C. | Numerisch / intervallskaliert | kein Nullpunkt |
| n1 | Alter | 22 | Numerisch / verhältnisskal. | keine Negativwerte |

## Skalenniveau am Beispiel

| title | year | budget | avg_vote |
|------------------|------------------|------------------|------------------|
| Miss Jerry | 1894 | NA | 5.9 |
| The Story of the Kelly Gang | 1906 | \$ 2250 | 6.1 |
| Den sorte drøm | 1911 | NA | 5.8 |
| Cleopatra | 1912 | \$ 45000 | 5.2 |
| L'Inferno | 1911 | NA | 7.0 |
| From the Manger to the Cross; or, Jesus of Nazareth | 1912 | NA | 5.7 |
| Madame DuBarry | 1919 | NA | 6.8 |
| Quo Vadis? | 1913 | ITL 45000 | 6.2 |
| Independenta Romaniei | 1912 | ROL 400000 | 6.7 |
| Richard III | 1912 | \$ 30000 | 5.5 |

## Analytische Konzepte

| Phase & Leitfrage | Statistisches Äquivalent | Beispiel‑Methoden / Tools |
|------------------------|------------------------|------------------------|
| **Rückblick – Was ist passiert?** | **Deskriptive Statistik** | Lage‑ & Streuungsmaße, Häufigkeiten, Balken‑/Liniendiagramme |
| **Erkenntnis – Warum passiert es?** | **Explorative & inferenzielle Statistik** | Korrelation, t‑Test, ANOVA, χ²‑Test, Konfidenz­intervalle, Regressionsdiagnostik |
| **Vorausschau – Was wird passieren?** | **Prognostische (inferenzielle) Modelle** | Lineare/Logistische Regression, Random Forest, Zeitreihen‑Forecasts, Konfidenz­intervalle für Prognosen |
| **Vorausschau – Was muss passieren, damit es eintritt?** | **Präskriptive (inferenzielle) Verfahren** | Simulation (Monte‑Carlo), Lineare/Ganzzahl‑Optimierung, Entscheidungsbäume mit Unsicherheits‑Berücksichtigung |

## Wo finde ich Daten?

-   Kaggle
-   Statistisches Bundesamt
-   ...

## Warum nutzen wir R?

![](images/r-vs-python.png)

## R, Python, SPSS, ...

-   SPSS
-   SAS
-   Python
-   Scala
-   Julia
-   PSPP
-   R

## Die Programmiersprache R

-   R: Statistische Programmiersprache und Umgebung
-   Nachfolger von S (Unnützes Wissen, Teil 1)
-   Großer Vorteil: R ist von Statistikern für Statistiker
-   Großer Nachteil: R ist von Statistikern für Statistiker
-   Open Source
-   Packages (Libraries) erweitern den Umfang

## Die IDE RStudio

-   "Wenn R ein Pferd ist, dann ist RStudio der Sattel."
-   Entwickelt von RStudio PBC, heute Posit PBC
-   Kostenlos für den Heimgebrauch

## Die Arbeitsumgebung

-   Sozusagen der “Arbeitsspeicher”
-   Enthält nicht nur Objekte, sondern auch Packages
-   Häufige Fehlerursache: -- Man geht davon aus, dass etwas geladen ist, ist es aber nicht. -- Man geht davon aus, dass etwas nicht geladen ist, ist es aber.
-   R lädt alles (!) in den Arbeitsspeicher.

## Die ersten Schritte mit R

-   R als Taschenrechner
-   Objekt- und Funktionsstruktur in R
-   Zuordnung über `<-`
-   Hilfe über `?FUNKTIONSNAME`

## Funktionen

-   Funktionsstruktur: `funktionsname(Parameter)`
-   Beispiele: `plot()`, `summary()`, `str()`

## Datentypen in R

-   Character
-   Numerisch: integer und double
-   Factor
-   Datum
-   Dynamic typing und Bedeutung korrekter Datentypen

## Datenstrukturen in R

![](images/data-structures.png)

## Datenstrukturen in R

-   Vektor: Liste mit gleichen Datentypen
-   Dataframe: Tabelle mit Vektoren als Spalten
-   Liste: verschiedene Datentypen
-   Matrix: Tabelle nur mit gleichen Datentypen
-   Array: Dreidimensionale Matrix

## Dataframes

-   Zentrales Konzept in R
-   Struktur: Zeilen für Observationen, Spalten für Attribute
-   Zugriff auf Spalten über Dollarzeichen (`$`)

# Sitzung 2: Deskriptive Statistik I

## Let's talk about money

![](images/einkommen.jpeg)

## Wie könnte man die Einkommensverteilung beschreiben?

![](images/einkommensschichtung.png)

## Histogramm

-   Was: Grafische Darstellung der Häufigkeitsverteilung in Klassen
-   Bestandteile: X-Achse (Werte), Y-Achse (Häufigkeit), Balken (Klassenhäufigkeit)
-   Wozu: Schneller Überblick über Datenverteilung und -muster
-   Interpretation: Form (symmetrisch/schief), Modalität (uni-/multimodal), Ausreißer
-   Wichtig: Klassenanzahl beeinflusst sichtbare Form
-   In R: `hist(data, breaks = 10)`

## Warum sind statistische Kennzahlen wichtig?

## Daten zusammenfassen und vereinfachen

-   **Reduktion von Komplexität**: Große Datenmengen werden durch wenige Werte beschreibbar
-   **Kommunikation**: Leichtere Vermittlung von Erkenntnissen an Nicht-Statistiker
-   **Vergleichbarkeit**: Unterschiedliche Datensätze werden vergleichbar

## Entscheidungsgrundlage in vielen Anwendungsbereichen

-   **Wirtschaft**: Grundlage für Investitionsentscheidungen und Marktanalysen
-   **Medizin**: Interpretation von Studienergebnissen und diagnostischen Tests
-   **Politik**: Faktenbasis für gesellschaftliche und wirtschaftliche Maßnahmen
-   **Wissenschaft**: Prüfung von Hypothesen und Interpretation von Experimenten

## Typische Anwendungsfälle

| Kennzahl | Wichtig für... | Beispielanwendung |
|------------------------|------------------------|------------------------|
| **Mittelwert** | Durchschnittswerte, Summenbetrachtungen | Durchschnittseinkommen einer Region |
| **Median** | Typische Werte, robust gegen Ausreißer | Typisches Haushaltseinkommen |
| **Standardabweichung** | Streuung, Qualitätskontrolle | Produktionsgenauigkeit in der Fertigung |
| **Quartile/Boxplot** | Verteilungsform, Ausreißererkennung | Identifikation von Ungleichheiten |
| **Schiefe/Wölbung** | Abweichungen von der Normalverteilung | Risikobewertung im Finanzwesen |

## Von der Beschreibung zur Inferenz

-   Deskriptive Statistik als Grundlage für **statistische Tests**
-   Möglichkeit der **Stichprobenerhebung** statt Vollerhebung
-   Basis für **statistische Modellierung** und **Vorhersagen**

## Erkennung von Mustern und Besonderheiten

-   **Ausreißer**: Potentielle Fehler oder besondere Fälle
-   **Trends**: Entwicklungen über Zeit
-   **Gruppenunterschiede**: Systematische Variation zwischen Teilgruppen

## Typisch / ungewöhnlich / unmöglich

![](images/hadlum.png)

## Weitere Beispiele

| Anwendungsgebiet | Kennzahlen | Nutzen |
|------------------------|------------------------|------------------------|
| **Medizin** | Referenzwerte (z.B. Blutdruck, BMI) | Diagnostik, Risikoeinschätzung |
| **Finanzmarkt** | Volatilität (Standardabweichung) | Risikobewertung von Anlagen |
| **Qualitätssicherung** | Prozessfähigkeitsindizes (basierend auf σ) | Optimierung von Produktionsprozessen |
| **Sozialforschung** | Gini-Koeffizient (basierend auf Verteilung) | Ungleichheitsmaße in der Gesellschaft |
| **Meteorologie** | Durchschnittstemperaturen + Extremwerte | Klimaforschung, Wettervorhersage |

## Lagemaße

![](images/mean-mode-median.png)

## Lagemaße

-   Mean bezeichnet das arithmetische Mittel, häufig als „Durchschnitt" bezeichnet: mean()
-   Neben dem arithmetischen Mittel existieren weitere Mittelwerte, zum Beispiel das geometrische Mittel
-   Der Median ist weniger anfällig für Ausreißer: median()
-   Der Modalwert kann auch mit kategorialen Variablen umgehen
-   In R existiert kein Befehl für den Modalwert ☹

## Merke

![](images/meme-durchschnitt.png)

## It really happened

![](images/clinton-average.png)

## Auch die MOPO...

![](images/Bildschirmfoto%202025-05-09%20um%2011.34.35.png)

## Streuungsmaße

## Spannweite (Range)

-   Die Spannweite ist der einfachste Streuungsparameter
-   Berechnung: Maximum - Minimum
-   Sehr anfällig für Ausreißer
-   In R: `diff(range(data))` oder `max(data) - min(data)`

## Interquartilsabstand (IQR)

-   Robusteres Streuungsmaß, das Ausreißer besser berücksichtigt
-   Berechnung: 75%-Quartil minus 25%-Quartil (Q3 - Q1)
-   Enthält die mittleren 50% der Daten
-   In R: `IQR(data)` oder `quantile(data, 0.75) - quantile(data, 0.25)`

## Varianz

-   Durchschnittliche quadratische Abweichung vom Mittelwert
-   Berechnung für Grundgesamtheit: $$\sigma^2 = \frac{1}{N} \sum_{i=1}^{N} (x_i - \mu)^2$$
-   Berechnung für Stichprobe (korrigierte Varianz): $$s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2$$
-   Einheit: Quadrat der Einheit der Ursprungsdaten
-   In R: `var(data)`

## Standardabweichung

![](images/Standard_deviation_diagram.svg.png)

## Standardabweichung

-   Wurzel aus der Varianz: Dieselbe Einheit wie die Ursprungsdaten
-   Berechnung für Grundgesamtheit: $$\sigma = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (x_i - \mu)^2}$$
-   Berechnung für Stichprobe: $$s = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2}$$
-   In R: `sd(data)`

## Interpretation der Standardabweichung im Kontext der Normalverteilung

-   Bei normalverteilten Daten liegen ca. 68% der Werte innerhalb von μ ± σ (Mittelwert ± 1 Standardabweichung)
-   Ca. 95% der Werte liegen innerhalb von μ ± 2σ
-   Ca. 99,7% der Werte liegen innerhalb von μ ± 3σ ("Drei-Sigma-Regel")

## Formparameter

![](images/3-s2.0-B9780128207178000087-f05-03-9780128207178.jpg)

## Schiefe (Skewness)

-   Misst die Asymmetrie einer Verteilung
-   Positive Schiefe: rechtsschiefe Verteilung (längerer "Schwanz" nach rechts)
-   Negative Schiefe: linksschiefe Verteilung (längerer "Schwanz" nach links)
-   Schiefe von 0: symmetrische Verteilung (z.B. Normalverteilung)
-   In R: `skewness(data)` aus dem Paket **moments** oder **e1071**

## Wölbung (Kurtosis)

-   Misst die "Spitzheit" bzw. "Flachheit" einer Verteilung
-   Normalverteilung hat eine Kurtosis von 3 (manchmal als Exzess-Kurtosis = 0 dargestellt)
-   Hohe Kurtosis (\>3): spitze Verteilung mit "schweren Enden" (mehr Extremwerte)
-   Niedrige Kurtosis (\<3): flache Verteilung mit "leichten Enden" (weniger Extremwerte)
-   In R: `kurtosis(data)` aus dem Paket **moments** oder **e1071**

## Positionskennwerte

## Quantile und Perzentile

-   Teile die Daten in gleich große Teile
-   Median = 0,5-Quantil (50%-Perzentil)
-   Quartile teilen die Daten in vier gleiche Teile:
    -   Q1 = 0,25-Quantil (25%-Perzentil)
    -   Q2 = 0,5-Quantil (50%-Perzentil) = Median
    -   Q3 = 0,75-Quantil (75%-Perzentil)
-   In R: `quantile(data, probs = c(0.25, 0.5, 0.75))` für Quartile

## Boxplot

![](images/Elements_of_a_boxplot.svg.png)

## Boxplot

-   Visuelle Darstellung von Quartilen und Ausreißern
-   Box: Interquartilsabstand (IQR) von Q1 bis Q3
-   Mittellinie: Median (Q2)
-   Whiskers: Typischerweise bis max. 1,5 × IQR von der Box
-   Punkte außerhalb der Whiskers: potenzielle Ausreißer
-   In R: `boxplot(data)`

\#![](images/boxplot-explained.png)

## Wie macht man das in R?

| Kennzahl | R‑Befehl | Kurzbeschreibung |
|------------------------|------------------------|------------------------|
| Mittelwert | `mean(data)` | Durchschnitt aller Werte |
| Median | `median(data)` | Zentralwert (50 %-Quantil) |
| Minimum | `min(data)` | Kleinster Wert |
| Maximum | `max(data)` | Größter Wert |
| Spannweite | `diff(range(data))` | Abstand = Max − Min |
| Standardabweichung | `sd(data)` | Ø‑Abweichung vom Mittelwert |
| Varianz | `var(data)` | Quadrat der Standardabweichung |
| Schiefe | `skewness(data)` *(moments/e1071)* | Asymmetrie der Verteilung |
| Wölbung (Kurtosis) | `kurtosis(data)` *(moments/e1071)* | "Spitzheit" der Verteilung |
| Quantile | `quantile(data, c(.25,.5,.75))` | 25 %, 50 %, 75 %-Werte (Quartile) |

## Übung mit dem Datensatz iris

| Kennzahl           | R‑Befehl            | Kurzbeschreibung               |
|--------------------|---------------------|--------------------------------|
| Mittelwert         | `mean(data)`        | Durchschnitt aller Werte       |
| Median             | `median(data)`      | Zentralwert (50 %-Quantil)     |
| Minimum            | `min(data)`         | Kleinster Wert                 |
| Maximum            | `max(data)`         | Größter Wert                   |
| Spannweite         | `diff(range(data))` | Abstand = Max − Min            |
| Standardabweichung | `sd(data)`          | Ø‑Abweichung vom Mittelwert    |
| Varianz            | `var(data)`         | Quadrat der Standardabweichung |

# Sitzung 3: Deskriptive Statistik II & Datenmanipulation

## Typischer Ablauf

![](images/CRISP-DM_Process_Diagram.png)

## Tidyverse

-   Das Tidyverse-Paket von Hadley Wickham
-   Code the way you think
-   Enthält Packages wie dplyr und readr

## Packages laden und installieren

-   Packages als Erweiterungen zu base R
-   Installation über Tools =\> Install Packages
-   Laden über library(NAME)
-   tidyverse und nycflights23

## Rohdaten transformieren und zusammenfassen

Beschreiben Sie die Schritte, um eine Tüte Gummibärchen nach Farben zu sortieren

## Rohdaten transformieren und zusammenfassen

![](images/gummibaerchen.png)

-   Öffne die Gummibärchentüte
-   Gruppiere die Gummibärchen nach Farbe
-   Zähle die Gummibärchen pro Farbe durch
-   Zugabe: Sortiere absteigend nach Häufigkeit

## Rohdaten transformieren und zusammenfassen

``` r
Gummibärchentüte %>%
  group_by(farbe) %>%
  summarize(Anzahl = n()) %>%
  arrange(desc(Anzahl))
```

## Typische Funktionen in Tidyverse

-   `group_by()`: Gruppieren nach Variablen
-   `select()`: Spalten auswählen
-   `filter()`: Zeilen nach Werten filtern
-   `mutate()`: Variablen erstellen oder modifizieren
-   `summarise()`: Mehrere Werte zu einem Ergebnis reduzieren
-   `arrange()`: Sortierung ändern

## Ausprobieren mit nycflights23

-   5 Datensätze
    -   flights
    -   planes
    -   airlines
    -   airports
    -   weather

## Demo

## Typische Fehler

-   Package nicht geladen
-   Pipe-Symbol falsch verwendet
-   Unvollständige Code-Chunks

## Datensätze miteinander verbinden

![](images/joins.png)

## Daten lesen und schreiben

-   Dateiformate: CSV, JSON, ARFF, Excel, Parquet, u.a.
-   Was sind die Vor- und Nachteile der Formate?
-   Import-Beispiele

## Pro-Tipp

-   Importzeile aus Code Preview kopieren und ins Notebook kopieren
-   library ignorieren (haben wir schon mit dem Tidyverse importiert)
-   View(gadata) ignorieren (nervt nur)

# Sitzung 4: Datenvisualisierung

## Warum Datenvisualisierung?

> The greatest value of a picture is when it forces us to notice what we never expected to see. (John Tukey)

## 5 wichtige Schritte

1.  Was ist der Kontext?
    -   An wen wird kommuniziert?
    -   Was soll der Empfänger wissen oder tun?
    -   Welche Daten sind vorhanden, um den Case zu untermauern?
2.  Welche ist das passendste Visualierung?
    -   Ein oder zwei Zahlen, die im Fokus stehen? =\> Text!
    -   Liniendiagramme für continuous data
    -   Säulendiagramme für kategoriale Daten, müssen bei 0 anfangen
    -   Die Beziehungen der Daten untereinander bestimmen die Visualisierung, sofern Sie mehr als eine Variable haben
    -   Vermeiden Sie Tortendiagramme, Donuts, 3D, zweite Y-Achsen

## 5 wichtige Schritte, Teil II

3.  Entfernen Sie „Clutter"
    1.  Entfernen Sie alles, das keinen informativen Mehrwert hat (z.B. Farben für die Ästhetik)
    2.  Arbeiten Sie mit freiem Raum
4.  Fokussieren Sie die Aufmerksamkeit, wo Sie hin soll
    -   Größe, Position und, ja, manchmal auch Farbe nutzen um zu signalisieren, was wichtig ist
    -   Wohin gehen die Augen?
5.  Nutzen Sie Storytelling
    -   Niemand will einfach nur Auflistungen von Zahlen und Diagrammen sehen.
    -   Schreiben Sie einen Plot. Anfang, eventuell sogar einen Twist, und ein Ende mit Call to Action (in der Wissenschaft reicht eine Diskussion ☺)
    -   Bitte arbeiten Sie nicht einfach nur mechanisch alles ab, was Sie können.

## Redundant Coding

„Redundant Coding"

## Weitere Prinzipien der Visualisierung

Weißer Space ist gut… aber nicht zu viel!

## Weitere Prinzipien der Visualisierung

Highlighting hilft auf das zu fokussieren, was wirklich wichtig ist

## Wie identifiziert man das richtige Diagramm?

## Scatter Plot / Streudiagramm

::::: columns
::: {.column width="60%"}
-   Zeigt Beziehung zwischen zwei kontinuierlichen Variablen
-   Jeder Punkt = eine Beobachtung
-   Erkennt Muster, Cluster, Ausreißer und Korrelationen
-   Benötigt numerische X/Y-Achsen
-   Dritte Dimension durch Punktgröße/Farbe möglich
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
set.seed(42)
scatter_data <- data.frame(
  x = rnorm(100),
  y = rnorm(100),
  gruppe = sample(LETTERS[1:3], 100, replace = TRUE)
)
# Korrelation hinzufügen
scatter_data$y <- scatter_data$y + scatter_data$x - 0.7 + rnorm(100, 0, 0.5)
ggplot(scatter_data, aes(x = x, y = y, color = gruppe)) +
  geom_point(size = 3, alpha = 0.7) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal() +
  labs(x = "Variable X", y = "Variable Y", color = "Gruppe")
```
:::
:::::

## Korrelationsmatrix

::::: columns
::: {.column width="60%"}
-   Zeigt Korrelationsstärke zwischen Variablen
-   Farbe/Größe visualisiert Richtung und Stärke
-   Unterscheidet klar positive/negative Korrelationen
-   Identifiziert Muster und redundante Variablen
-   Essentiell für explorative Datenanalyse
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
library(reshape2)

# Direkt eine gültige Korrelationsmatrix erstellen
set.seed(123)
vars <- 5
varNames <- LETTERS[1:vars]

# Simulierte Daten direkt erstellen
sim_data <- data.frame(
  A = rnorm(100),
  B = rnorm(100),
  C = rnorm(100),
  D = rnorm(100),
  E = rnorm(100)
)
# Korrelationen hinzufügen
sim_data$B <- sim_data$B + sim_data$A - 0.7 + rnorm(100, 0, 0.5)
sim_data$C <- sim_data$C - sim_data$A - 0.4 + rnorm(100, 0, 0.5)
sim_data$D <- sim_data$D + sim_data$B - 0.6 + rnorm(100, 0, 0.5)
sim_data$E <- sim_data$E - sim_data$C - 0.5 + sim_data$D - 0.3 + rnorm(100, 0, 0.5)

# Korrelationsmatrix berechnen
cormat <- round(cor(sim_data), 2)
melted_cormat <- melt(cormat)

ggplot(melted_cormat, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "firebrick", high = "steelblue", mid = "white", 
                     midpoint = 0, limit = c(-1,1)) +
  geom_text(aes(label = round(value, 2)), color = "black", size = 3) +
  theme_minimal() +
  coord_equal() +
  labs(fill = "Korrelation")
```
:::
:::::

## Venn-Diagramm

::::: columns
::: {.column width="60%"}
-   Zeigt gemeinsame und einzigartige Elemente
-   Überschneidungen visualisieren Gemeinsamkeiten
-   Ideal für Vergleich von Kategorien/Merkmalen
-   Funktioniert am besten mit 2-3 Gruppen
-   Wird mit mehr als 5 Gruppen unübersichtlich
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
# Vereinfachtes Venn-Diagramm mit ggplot2
theta <- seq(0, 2-pi, length.out = 100)
circle <- data.frame(
  x = cos(theta),
  y = sin(theta)
)
ggplot() +
  # Kreis A
  geom_polygon(data = circle, aes(x = x-1.2 - 0.5, y = y-1.2), 
               fill = "steelblue", alpha = 0.5) +
  # Kreis B
  geom_polygon(data = circle, aes(x = x-1.2 + 0.5, y = y-1.2), 
               fill = "firebrick", alpha = 0.5) +
  # Labels
  annotate("text", x = -1, y = 0, label = "A", size = 6, fontface = "bold", color = "white") +
  annotate("text", x = 1, y = 0, label = "B", size = 6, fontface = "bold", color = "white") +
  annotate("text", x = 0, y = 0, label = "A ∩ B", size = 5, fontface = "bold") +
  theme_void() +
  coord_equal()
```
:::
:::::

## UpSet Diagram

::::: columns
::: {.column width="60%"}
-   Alternative für komplexe Überschneidungen
-   Skalierbarer als klassische Venn-Diagramme
-   Balken visualisieren Überschneidungsgrößen
-   Punkte zeigen beteiligte Mengen
-   Ideal für 4+ Gruppen/komplexe Beziehungen
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
# Vereinfachtes UpSet-Diagramm mit ggplot2
sets <- c("A", "B", "C")
combinations <- data.frame(
  sets = c("A", "B", "C", "A∩B", "A∩C", "B∩C", "A∩B∩C"),
  size = c(15, 10, 12, 8, 6, 5, 3),
  A = c(1, 0, 0, 1, 1, 0, 1),
  B = c(0, 1, 0, 1, 0, 1, 1),
  C = c(0, 0, 1, 0, 1, 1, 1)
)
# Oberer Teil: Set-Größen
p1 <- ggplot(combinations[1:3,], aes(x = sets, y = size)) +
  geom_bar(stat = "identity", fill = "grey60", width = 0.6) +
  theme_minimal() +
  labs(x = NULL, y = "Set-Größe") +
  theme(axis.text.x = element_text(angle = 0))
# Unterer Teil: Überschneidungen
p2 <- ggplot(combinations[4:7,], aes(x = sets, y = size)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.6) +
  theme_minimal() +
  labs(x = "Überschneidungen", y = "Größe") +
  theme(axis.text.x = element_text(angle = 0, size = 8))
gridExtra::grid.arrange(p1, p2, heights = c(1, 2))
```
:::
:::::

## Sankey Diagram

::::: columns
::: {.column width="60%"}
-   Visualisiert Flüsse zwischen Kategorien
-   Pfeilbreite zeigt Volumen/Wert
-   Ideal für Verteilungen und Prozesse
-   Zeigt Herkunft und Ziel von Ressourcen
-   Verdeutlicht Proportionen über mehrere Stufen
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
library(ggalluvial)
# Sankey/Alluvial Diagramm
sankey_data <- data.frame(
  Quelle = rep(c("A", "B", "C"), times = c(3, 2, 2)),
  Ziel = c("X", "Y", "Z", "X", "Y", "Y", "Z"),
  Wert = c(5, 3, 2, 2, 3, 1, 4)
)
ggplot(sankey_data, aes(axis1 = Quelle, axis2 = Ziel, y = Wert)) +
  geom_alluvium(aes(fill = Quelle), width = 1/3) +
  geom_stratum(width = 1/3, fill = "grey80", color = "grey50") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal() +
  labs(x = NULL, y = NULL) +
  theme(legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks = element_blank())
```
:::
:::::

## Horizontal Bar Chart

::::: columns
::: {.column width="60%"}
-   Vergleicht Werte über Kategorien hinweg
-   Horizontale Anordnung für bessere Lesbarkeit
-   Ideal für lange Namen oder viele Kategorien
-   Perfekt für Rankings und Wertvergleiche
-   Einfach und übersichtlich
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
hbar_data <- data.frame(
  kategorie = c("Kategorie mit sehr langem Namen A", 
                "Kategorie B", 
                "Kategorie C", 
                "Kategorie D", 
                "Kategorie E"),
  wert = c(85, 72, 56, 41, 25)
)
ggplot(hbar_data, aes(x = reorder(kategorie, wert), y = wert)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Wert") +
  geom_text(aes(label = wert), hjust = -0.2) +
  ylim(0, max(hbar_data$wert) - 1.15)
```
:::
:::::

## Column Chart

::::: columns
::: {.column width="60%"}
-   Vergleicht Werte mit vertikalen Balken
-   Ideal für Ranking und Leistungsvergleiche
-   Funktioniert gut mit wenigen, klaren Kategorien
-   Kurze, lesbare Beschriftungen bevorzugen
-   Konsistente Nullbasislinie für faire Vergleiche
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
column_data <- data.frame(
  kategorie = factor(c("A", "B", "C", "D", "E"), levels = c("A", "B", "C", "D", "E")),
  wert = c(85, 72, 56, 41, 25)
)
ggplot(column_data, aes(x = kategorie, y = wert, fill = kategorie)) +
  geom_bar(stat = "identity", width = 0.7) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  labs(x = NULL, y = "Wert") +
  theme(legend.position = "none") +
  geom_text(aes(label = wert), vjust = -0.5) +
  ylim(0, max(column_data$wert) - 1.1)
```
:::
:::::

## Comparison: Horizontal vs. Vertical Bar Charts

Use horizontal when the text matters more. Use vertical when the order or time is key.

| Feature | Horizontal | Vertical |
|------------------------|------------------------|------------------------|
| Best for | Long category labels, many items | Time-based or logical progression |
| Readability | Easier when labels are long | Requires rotation for long labels |
| Use case | Rankings, survey responses | Trends over time, grouped comparisons |
| Scan direction | Left to right | Bottom to top |
| Visual space | Efficient for many categories | Better for fewer, high-impact bars |

## Circular Bar Plot

::::: columns
::: {.column width="60%"}
-   Kreisförmige Darstellung von Werten mit Kategorien
-   Farbcodierung zeigt Gruppenzugehörigkeit
-   Kompakte Darstellung von Mustern und Beziehungen
-   Ideal für visuelles Storytelling
-   Beschriftungen sparsam und deutlich halten
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
library(dplyr)
data <- data.frame(
  category = rep(LETTERS[1:4], each = 5),
  subcategory = rep(1:5, 4),
  value = sample(20:100, 20)
)
ggplot(data, aes(x = subcategory, y = value, fill = category)) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_polar() +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal()
```
:::
:::::

## Diverging Bars

::::: columns
::: {.column width="60%"}
-   Zeigt Abweichungen in zwei Richtungen
-   Links/rechts von zentraler Basislinie
-   Ideal für Kontraste (positiv/negativ)
-   Zeigt Gleichgewicht vs. Ungleichgewicht
-   Gut für normalisierte Werte oder Z-Scores
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
diverging_data <- data.frame(
  category = factor(LETTERS[1:8], levels = LETTERS[8:1]),
  value = c(5, -2, 8, -3, 6, -1, 4, -7)
)
ggplot(diverging_data, aes(x = category, y = value, fill = value > 0)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("firebrick", "steelblue"), guide = "none") +
  coord_flip() +
  theme_minimal() +
  labs(y = "Abweichung vom Mittelwert")
```
:::
:::::

## Diverging Lollipop Chart

::::: columns
::: {.column width="60%"}
-   Elegantere Alternative zu Diverging Bars
-   Nutzt Punkte statt Balken (weniger Tinte)
-   Zeigt Richtung und Magnitude effektiv
-   Ideal wenn genaue Werte sekundär sind
-   Besonders gut für Präsentationen
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
lollipop_data <- data.frame(
  category = factor(LETTERS[1:8], levels = LETTERS[8:1]),
  value = c(5, -2, 8, -3, 6, -1, 4, -7)
)
ggplot(lollipop_data, aes(x = category, y = value, color = value > 0)) +
  geom_segment(aes(y = 0, x = category, yend = value, xend = category), color = "grey") +
  geom_point(size = 3) +
  scale_color_manual(values = c("firebrick", "steelblue"), guide = "none") +
  coord_flip() +
  theme_minimal() +
  labs(y = "Abweichung vom Mittelwert")
```
:::
:::::

## Histogram

::::: columns
::: {.column width="60%"}
-   Zeigt Verteilung numerischer Daten in Bins
-   Balken zeigen Häufigkeiten in Wertebereichen
-   Erkennt Schiefe, Streuung und Ausreißer
-   Zeigt Modi und Clustering in Daten
-   Berührende Balken betonen Kontinuität
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
set.seed(123)
hist_data <- data.frame(
  value = c(rnorm(400, mean = 5, sd = 1), rnorm(100, mean = 8, sd = 0.5))
)
ggplot(hist_data, aes(x = value)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white") +
  theme_minimal() +
  labs(y = "Häufigkeit")
```
:::
:::::

## Boxplots

::::: columns
::: {.column width="60%"}
-   Zeigt Minimum, Quartile und Median
-   Kompakte Darstellung von Verteilungen
-   Hebt Streuung und Ausreißer hervor
-   Ideal zum Kategorienvergleich
-   Kann für Laien schwer verständlich sein
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
set.seed(123)
box_data <- data.frame(
  category = rep(c("A", "B", "C", "D"), each = 100),
  value = c(
    rnorm(100, mean = 5, sd = 1),
    rnorm(100, mean = 7, sd = 1.5),
    rnorm(100, mean = 4, sd = 0.8),
    rnorm(100, mean = 6, sd = 2)
  )
)
ggplot(box_data, aes(x = category, y = value, fill = category)) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set2", guide = "none") +
  theme_minimal()
```
:::
:::::

## Boxplots mit Violin Plot

::::: columns
::: {.column width="60%"}
-   Kombiniert Boxplot mit Dichteverteilung
-   Zeigt Form, Streuung und zentrale Tendenz
-   Ideal für Gruppenvergleiche
-   Verdeutlicht Schiefe und Multimodalität
-   Informationsreichere Alternative zum Boxplot
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
set.seed(123)
violin_data <- data.frame(
  category = rep(c("A", "B", "C"), each = 100),
  value = c(
    c(rnorm(50, 5, 1), rnorm(50, 8, 0.5)),
    rnorm(100, 7, 1.5),
    rnorm(100, 6, 0.7)
  )
)
ggplot(violin_data, aes(x = category, y = value, fill = category)) +
  geom_violin(alpha = 0.7) +
  geom_boxplot(width = 0.2, fill = "white", alpha = 0.7) +
  scale_fill_brewer(palette = "Set2", guide = "none") +
  theme_minimal()
```
:::
:::::

## Choropleth Map

::::: columns
::: {.column width="60%"}
-   Färbt Regionen basierend auf Datenwerten
-   Zeigt räumliche Muster und Unterschiede
-   Gut für Verhältnisse und Prozentsätze
-   Nutze normalisierte Daten (pro Kopf, %)
-   Vorsicht bei großen Flächenunterschieden
:::

::: {.column width="40%"}
![](images/map.png)
:::
:::::

## Stacked Area Chart

::::: columns
::: {.column width="60%"}
-   Zeigt Kategorienbeiträge im Zeitverlauf
-   Gestapelte Schichten zeigen Gesamtsumme
-   Gut für Wachstum und Anteile
-   Funktioniert am besten mit wenigen Kategorien
-   Einzelsegmentvergleich schwierig
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
set.seed(42)
years <- 2010:2020
area_data <- data.frame(
  year = rep(years, 4),
  category = rep(c("A", "B", "C", "D"), each = length(years)),
  value = c(
    10:20 + rnorm(11, 0, 1),
    20:30 - rnorm(11, 0, 1),
    15:25 + rnorm(11, 0, 2),
    25:35 + rnorm(11, 0, 1.5)
  )
)
ggplot(area_data, aes(x = year, y = value, fill = category)) +
  geom_area() +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal()
```
:::
:::::

## Stacked 100% Area Chart

::::: columns
::: {.column width="60%"}
-   Zeigt relative Anteile, nicht absolute Werte
-   Verfolgt Änderungen von Kategorienanteilen
-   Summe immer 100% für leichte Vergleichbarkeit
-   Fokus auf Zusammensetzung, nicht Wachstum
-   Absolute Trends gehen verloren
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
set.seed(42)
years <- 2010:2020
area100_data <- data.frame(
  year = rep(years, 4),
  category = rep(c("A", "B", "C", "D"), each = length(years)),
  value = c(
    10:20 + rnorm(11, 0, 1),
    20:30 - rnorm(11, 0, 1),
    15:25 + rnorm(11, 0, 2),
    25:35 + rnorm(11, 0, 1.5)
  )
)
ggplot(area100_data, aes(x = year, y = value, fill = category)) +
  geom_area(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  labs(y = "Anteil")
```
:::
:::::

## Waterfall Diagram

::::: columns
::: {.column width="60%"}
-   Zeigt Beiträge zu einer Gesamtsumme
-   Visualisiert Zu- und Abnahmen über Kategorien
-   Hebt schrittweise Veränderungen hervor
-   Ideal für Gewinn- oder Budgetanalysen
-   Zeigt Faktoren für das Endergebnis
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
waterfall_data <- data.frame(
  stage = factor(c("Start", "Einnahmen", "Kosten", "Steuern", "Ende"), 
                levels = c("Start", "Einnahmen", "Kosten", "Steuern", "Ende")),
  value = c(0, 50, -30, -10, 0),
  end = c(100, 150, 120, 110, 110),
  start = c(100, 100, 150, 120, 110),
  type = c("total", "in", "out", "out", "total")
)
ggplot(waterfall_data, aes(x = stage, y = value, fill = type)) +
  geom_rect(aes(x = stage, xmin = as.numeric(stage) - 0.4, 
                xmax = as.numeric(stage) + 0.4, 
                ymin = pmin(start, end), ymax = pmax(start, end)), color = "black") +
  scale_fill_manual(values = c("in" = "steelblue", "out" = "firebrick", "total" = "darkgrey"), 
                    guide = "none") +
  theme_minimal() +
  labs(y = "Wert")
```
:::
:::::

## Heatmap

::::: columns
::: {.column width="60%"}
-   Nutzt Farbintensität für Matrixwerte
-   Zeigt Muster, Cluster und Anomalien
-   Gut für Korrelationen und Zeitreihen
-   Einfach zu überblicken, weniger präzise
-   Farbskala entscheidend für Interpretation
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
set.seed(42)
n <- 10
heatmap_data <- expand.grid(x = 1:n, y = 1:n)
heatmap_data$value <- matrix(rnorm(n^2), n, n)[cbind(heatmap_data$x, heatmap_data$y)]
ggplot(heatmap_data, aes(x = x, y = y, fill = value)) +
  geom_tile() +
  scale_fill_viridis_c() +
  theme_minimal() +
  coord_equal() +
  labs(x = "", y = "")
```
:::
:::::

## Square Area Chart

::::: columns
::: {.column width="60%"}
-   Zeigt Anteile mit gleichgroßen Quadraten
-   Typisch: 1 Quadrat = 1% (10×10-Raster)
-   Ideal für einfache Proportionsdarstellung
-   Leicht lesbar und ansprechend
-   Am besten mit wenigen Kategorien
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
square_data <- data.frame(
  x = rep(1:10, 10),
  y = rep(1:10, each = 10),
  category = c(rep("A", 40), rep("B", 25), rep("C", 20), rep("D", 15))
)
ggplot(square_data, aes(x = x, y = y, fill = category)) +
  geom_tile(color = "white") +
  scale_fill_brewer(palette = "Set2") +
  coord_equal() +
  theme_void() +
  labs(fill = "Kategorie")
```
:::
:::::

## Treemap

::::: columns
::: {.column width="60%"}
-   Zeigt Teil-Ganzes-Beziehungen mit Rechtecken
-   Größe entspricht dem Wert (Umsatz, Anzahl)
-   Visualisiert Hierarchien und Gruppierungen
-   Gut für Proportionsvergleiche
-   Vorsicht bei zu vielen kleinen Elementen
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 5
#| fig-height: 5
library(ggplot2)
library(treemapify)
treemap_data <- data.frame(
  category = c("A", "B", "C", "D", "E", "F"),
  subcategory = c("A1", "B1", "C1", "D1", "E1", "F1"),
  value = c(25, 18, 12, 10, 8, 5)
)
ggplot(treemap_data, aes(area = value, fill = category, label = subcategory)) +
  geom_treemap() +
  geom_treemap_text(color = "white", fontface = "bold") +
  scale_fill_brewer(palette = "Set2") +
  theme_void()
```
:::
:::::

## Nein, Sie verwenden bitte keine Pie Charts!

\#![](images/pie-chart-problem.png)

## Was denken Sie über diese Grafik?

## Datenvisualisierung mit ggplot2

-   Base Plot vs. ggplot2
-   Grammar of Graphics
-   `geom_point()`, `geom_histogram()`, `geom_boxplot()`
-   Ästhetiken: Farbe, Form, Gruppierung

# Sitzung 5: Wahrscheinlichkeiten & Verteilungen

## Wahrscheinlichkeiten & Verteilungen

-   Intuitive Einführung in Zufall & Normalverteilung
-   Laplace, Simulation, `rnorm()`, `dnorm()`
-   Visualisierung von Wahrscheinlichkeitsdichte

## Zentrale Grenzwertsätze

-   Warum Mittelwerte normalverteilt sind
-   Simulationen mit `replicate()`, `mean()`
-   Stichprobenverteilungen

# Sitzung 6: Einführung in die Inferenzstatistik

## Klassische Statistische Inferenz

-   Konzepte der Nullhypothese und Alternativhypothese
-   Placebos und Behandlungsgruppen in Experimenten
-   Randomisierung

## Hypothesen

-   H0: Nullhypothese
-   H1: Alternativhypothese
-   Isolierbarkeit des Untersuchungsgegenstands
-   Arbeit mit Stichproben statt Grundgesamtheit

## Der Mittelwert einer Stichprobe

-   Stichprobenverteilung des Mittelwerts
-   Central Limit Theorem
-   Unsicherheiten in der Schätzung

## Konfidenzintervalle

-   Unsicherheiten abschätzen
-   Konfidenzintervall mit `t.test()`
-   Visualisierung von CI über Punkteschätzungen

## Hypothesentests

-   Testlogik verstehen
-   Null- und Alternativhypothese
-   Fehler 1. & 2. Art
-   Signifikanzniveau, p-Wert

## Experimente - Die Statistik-Pille

\#![](images/statistik-pille.png) - Mit dieser Pille schreiben Sie garantiert bessere Noten! Aber wie finden wir das heraus? - Experimentaufbau mit Test- und Kontrollgruppe - Blindtest versus Doppelblindtest

# Sitzung 7: t-Tests

## Historischer Hintergrund

-   Entwicklung durch William Sealy Gosset (unter Pseudonym "Student")
-   Ursprüngliche Anwendung in der Brauerei Guinness
-   Evolution von "Student's t-Test" zu modernen Varianten

::: notes
-   **William Sealy Gosset**: Entwickelte den t-Test 1908, während er bei der Guinness-Brauerei arbeitete. Da Guinness Mitarbeitern nicht erlaubte, zu publizieren, veröffentlichte er unter dem Pseudonym "Student".
-   **Ursprüngliche Anwendung**: Gosset brauchte eine Methode, um die Qualität von Brauerei-Rohstoffen mit kleinen Stichproben zu testen.
-   **Evolution**: Vom ursprünglichen "Student's t-Test" haben sich verschiedene Varianten entwickelt, um unterschiedlichen Forschungsfragen gerecht zu werden.
:::

## Theoretische Grundlagen

-   t-Verteilung
-   Freiheitsgrade
-   Unterschied zur Normalverteilung
-   Zentraler Grenzwertsatz

::: notes
-   **t-Verteilung**: Eine kontinuierliche Wahrscheinlichkeitsverteilung, die der Normalverteilung ähnelt, aber breitere "Schwänze" hat, was sie für kleine Stichproben geeigneter macht.
-   **Freiheitsgrade**: Bestimmen die Form der t-Verteilung. Bei großen Freiheitsgraden nähert sich die t-Verteilung der Normalverteilung an.
-   **Unterschied zur Normalverteilung**: Die t-Verteilung berücksichtigt die zusätzliche Unsicherheit, die durch die Schätzung der Populationsvarianz aus einer kleinen Stichprobe entsteht.
-   **Zentraler Grenzwertsatz**: Erklärt, warum wir den t-Test auch bei nicht perfekt normalverteilten Daten anwenden können, wenn die Stichprobe groß genug ist.
:::

## Arten von t-Tests

-   Einstichproben-t-Test
-   Zweistichproben-t-Test (unabhängig)
-   Gepaarter t-Test (abhängig)
-   Welch-Test (ungleiche Varianzen)

::: notes
-   **Einstichproben-t-Test**: Vergleicht den Mittelwert einer Stichprobe mit einem bekannten oder hypothetischen Wert.
-   **Zweistichproben-t-Test (unabhängig)**: Vergleicht die Mittelwerte zweier unabhängiger Gruppen.
-   **Gepaarter t-Test (abhängig)**: Vergleicht Mittelwerte von zwei verbundenen Messungen (z.B. vorher-nachher).
-   **Welch-Test**: Modifikation des t-Tests für den Fall ungleicher Varianzen, was eine häufige Verletzung der Annahmen des klassischen t-Tests ist.
:::

## Voraussetzungen

-   Normalverteilung
-   Varianzhomogenität (bei unabhängigem t-Test)
-   Unabhängigkeit der Beobachtungen
-   Skalenniveau der Daten

::: notes
-   **Normalverteilung**: Die Daten sollten annähernd normalverteilt sein. Bei großen Stichproben (n \> 30) ist der Test robust gegenüber Verletzungen dieser Annahme.
-   **Varianzhomogenität**: Bei unabhängigem t-Test sollten beide Gruppen ähnliche Varianzen aufweisen, sonst sollte der Welch-Test verwendet werden.
-   **Unabhängigkeit der Beobachtungen**: Die Daten sollten nicht durch Messwiederholungen oder Clustering beeinflusst sein (außer beim gepaarten t-Test).
-   **Skalenniveau der Daten**: Die abhängige Variable sollte metrisch sein (Intervall- oder Verhältnisskala).
:::

## Hypothesenbildung

-   Nullhypothese (H₀)
-   Alternativhypothese (H₁)
-   Gerichtete vs. ungerichtete Hypothesen
-   Fehler 1. und 2. Art

::: notes
-   **Nullhypothese (H₀)**: Typischerweise, dass kein Unterschied zwischen den Gruppen besteht oder der Stichprobenmittelwert dem Populationsmittelwert entspricht.
-   **Alternativhypothese (H₁)**: Die Gegenposition zur Nullhypothese, z.B. dass ein Unterschied existiert.
-   **Gerichtete vs. ungerichtete Hypothesen**: Ungerichtete testen auf generelle Unterschiede (≠), gerichtete auf spezifische Richtungen (\< oder \>).
-   **Fehler 1. und 2. Art**: Typ-I-Fehler = fälschliche Ablehnung der Nullhypothese (α); Typ-II-Fehler = fälschliche Beibehaltung der Nullhypothese (β).
:::

## Praktische Durchführung

-   Formelapparat
-   Berechnung der Teststatistik
-   Kritische Werte bestimmen
-   p-Wert-Berechnung

::: notes
-   **Formelapparat**: Zeige die relevanten Formeln für die Berechnung der t-Statistik je nach Art des t-Tests.
-   **Berechnung der Teststatistik**: Erklärung, wie Mittelwertdifferenz, Standardfehler und Freiheitsgrade zur t-Statistik kombiniert werden.
-   **Kritische Werte bestimmen**: Wie man anhand von t-Tabellen oder Software die kritischen Grenzen für die Entscheidung findet.
-   **p-Wert-Berechnung**: Erläuterung, dass der p-Wert die Wahrscheinlichkeit angibt, die beobachtete oder eine extremere Differenz zu erhalten, wenn H₀ wahr ist.
:::

## Effektstärken

-   Cohen's d
-   Hedges' g
-   Glass' Δ
-   Interpretation von Effektgrößen

::: notes
-   **Cohen's d**: Standardisierte Mittelwertdifferenz, übliche Interpretation: 0.2 = klein, 0.5 = mittel, 0.8 = groß.
-   **Hedges' g**: Korrektur von Cohen's d für kleine Stichproben.
-   **Glass' Δ**: Verwendet nur die Standardabweichung der Kontrollgruppe, nützlich bei ungleichen Varianzen.
-   **Interpretation von Effektgrößen**: Betone, dass Effektstärken oft aussagekräftiger sind als p-Werte, da sie die praktische Bedeutsamkeit eines Befundes zeigen.
:::

## Interpretation der Ergebnisse

-   Signifikanz vs. Relevanz
-   Konfidenzintervalle
-   Typische Fehlinterpretationen
-   Schlussfolgerungen formulieren

::: notes
-   **Signifikanz vs. Relevanz**: Ein statistisch signifikantes Ergebnis bedeutet nicht automatisch, dass es praktisch relevant ist.
-   **Konfidenzintervalle**: Geben zusätzlich zur Entscheidung "signifikant/nicht signifikant" einen Bereich für die wahre Effektgröße an.
-   **Typische Fehlinterpretationen**: p \< 0.05 bedeutet nicht, dass die Wahrscheinlichkeit der Nullhypothese \< 5% ist oder dass der Effekt zu 95% in der Population existiert.
-   **Schlussfolgerungen formulieren**: Wie man Ergebnisse korrekt und präzise in wissenschaftlicher Sprache formuliert.
:::

## Anwendungsbeispiele

-   Klinische Studien
-   Experimentelle Psychologie
-   A/B-Testing im Marketing
-   Qualitätskontrolle in der Produktion

::: notes
-   **Klinische Studien**: Vergleich von Behandlungs- und Kontrollgruppen, z.B. bei Medikamentenwirksamkeit.
-   **Experimentelle Psychologie**: Beispiele für typische psychologische Experimente, die mit t-Tests ausgewertet werden.
-   **A/B-Testing im Marketing**: Wie Unternehmen verschiedene Versionen von Websites oder Werbungen vergleichen.
-   **Qualitätskontrolle in der Produktion**: Anwendung von t-Tests zur Überwachung von Produktionsparametern.
:::

## Alternativen zum t-Test

-   Nichtparametrische Verfahren (Mann-Whitney-U, Wilcoxon)
-   ANOVA bei mehr als zwei Gruppen
-   Robuste Verfahren bei Verletzung der Voraussetzungen

::: notes
-   **Nichtparametrische Verfahren**: Wann Mann-Whitney-U oder Wilcoxon-Test als Alternative sinnvoll sind (bei Verletzung der Normalverteilungsannahme).
-   **ANOVA**: Bei mehr als zwei zu vergleichenden Gruppen als Erweiterung des t-Tests.
-   **Robuste Verfahren**: Trimmed-Mean-t-Tests und andere Ansätze, die weniger anfällig für Ausreißer sind.
:::

## Software-Implementierung

-   Umsetzung in R/Python/SPSS
-   Ausgabeinterpretation
-   Grafische Darstellung der Ergebnisse
-   Reproduzierbarkeit sicherstellen

::: notes
-   **Umsetzung in R/Python/SPSS**: Konkrete Codebeispiele für verschiedene Statistikprogramme.
-   **Ausgabeinterpretation**: Wie man die typische Ausgabe statistischer Software richtig liest und interpretiert.
-   **Grafische Darstellung**: Sinnvolle Visualisierungen für t-Test-Ergebnisse (Boxplots, Mittelwerte mit Konfidenzintervallen).
-   **Reproduzierbarkeit sicherstellen**: Tipps zur Dokumentation der Analyse für wissenschaftliche Transparenz.
:::

## Aktuelle Diskussion und Kritik

-   p-Wert-Problematik
-   Bayes'sche Alternativen
-   Replikationskrise
-   Power-Analysen und Stichprobenplanung

::: notes
-   **p-Wert-Problematik**: Die aktuelle Diskussion um die Überbetonung der Signifikanz und p-Hacking.
-   **Bayes'sche Alternativen**: Kurze Einführung in Bayes-Faktoren als Alternative zu p-Werten.
-   **Replikationskrise**: Wie mangelnde statistische Power und Publikationsbias zu nicht-replizierbaren Befunden führen können.
-   **Power-Analysen**: Betonung der Wichtigkeit adäquater Stichprobengrößen für zuverlässige t-Tests.
:::

## R-Code-Beispiel

```{r}
#| echo: true
#| eval: false

# Beispieldaten
gruppe_1 <- c(25, 28, 30, 32, 33, 35, 38, 40)
gruppe_2 <- c(20, 22, 24, 25, 28, 30, 31, 32)

# Unabhängiger t-Test
t.test(gruppe_1, gruppe_2, var.equal = TRUE)

# Welch-Test (ungleiche Varianzen)
t.test(gruppe_1, gruppe_2)

# Effektstärke berechnen
library(effsize)
cohen.d(gruppe_1, gruppe_2)
```

::: notes
Hier demonstriere ich einen typischen R-Code für die Durchführung eines t-Tests: - Der erste Test ist ein klassischer t-Test mit der Annahme gleicher Varianzen - Der zweite ist ein Welch-Test, der keine Varianzhomogenität voraussetzt - Das Effektstärkenmaß Cohen's d wird mit dem Paket "effsize" berechnet - In der Vorlesung könntest du diese Befehle live ausführen und die Ergebnisse besprechen
:::

## Visualisierung der Ergebnisse

```{r}
#| echo: true
#| eval: false

library(ggplot2)

# Daten vorbereiten
daten <- data.frame(
  Wert = c(gruppe_1, gruppe_2),
  Gruppe = factor(rep(c("Gruppe 1", "Gruppe 2"), each = 8))
)

# Boxplot erstellen
ggplot(daten, aes(x = Gruppe, y = Wert, fill = Gruppe)) +
  geom_boxplot() +
  geom_jitter(width = 0.2) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 3) +
  labs(title = "Vergleich der Gruppenmittelwerte", 
       y = "Messwert") +
  theme_minimal()
```

::: notes
Diese Visualisierung zeigt: - Boxplots für beide Gruppen, die die Verteilung veranschaulichen - Die einzelnen Datenpunkte als Punkte (Jitter verhindert Überlappungen) - Die Mittelwerte als größere Rauten - Diese Art der Darstellung ist informativer als ein einfacher Balkendiagramm, da sie die Streuung der Daten zeigt
:::

## t-Test

-   Mittelwertvergleiche anwenden
-   `t.test()` mit Beispieldaten
-   Voraussetzungen & Interpretation
-   Visualisierung mit ggplot2

## Vom Zentralen Grenzwertsatz zum t-Test

-   Stichprobenverteilung und Standardfehler
-   t-Verteilung bei unbekannter Populationsvarianz
-   Vergleich von Mittelwerten

## Guiness-Bier brachte die Lösung

-   William Sealy Gosset und die Entstehung der t-Verteilung
-   Bedeutung der Freiheitsgrade

## Die t-Verteilung

\#![](images/t-verteilung.png) - Eigenschaften im Vergleich zur Normalverteilung - Einfluss der Freiheitsgrade

## Wichtige Annahmen des t-Tests

-   Unabhängigkeit der Stichproben
-   Normalverteilung der Variablen
-   Metrische Variablen
-   Varianzhomogenität

## Was ist Signifikanz?

-   Definition des Signifikanzniveaus α
-   Interpretation des p-Werts
-   Häufige Fehlinterpretationen

## Fehler 1. und 2. Art

-   False Positive (α-Fehler)
-   False Negative (β-Fehler)
-   Sensitivität und Spezifität

## Ein- versus zweiseitiger Test

-   Wann ist welcher Test angemessen?
-   Auswirkungen auf p-Werte

## Praktische Anwendung

-   Reale Beispiele für t-Tests
-   Interpretation von Ergebnissen

## Sitzung 8: Umfragen und ANOVA

## Quantitativ versus Qualitativ

-   Unterschiede in Forschungsansätzen

## Datenerhebung

-   Primärdaten vs. Sekundärdaten
-   Umfragen, Interviews, Messungen

## Verzerrung zugunsten der Überlebenden

\#![](images/survivorship-bias.png)

## Stichprobenverzerrung

\#![](images/stichprobenverzerrung.png)

## Probleme bei Umfragen

-   Convenience Sampling
-   Non-Responder
-   Yes bias
-   No bias
-   Bias towards the middle
-   Soziale Erwünschtheit
-   Logical Response
-   Kulturelle Unterschiede (ein „Nein" ist nicht überall akzeptabel)

## Likert-Skala

-   Definition und Verwendung
-   Balance, Neutraloption, Skalenlänge
-   Vermeidung von Leading Questions

## Einführung in ANOVA

-   Analysis of Variance für mehr als zwei Gruppen
-   Nullhypothese: Alle Gruppenmittelwerte sind gleich
-   Alternativhypothese: Mindestens ein Gruppenmittelwert unterscheidet sich

## Voraussetzungen und Annahmen

-   Normalverteilung innerhalb der Gruppen
-   Homoskedastizität
-   Unabhängigkeit der Beobachtungen

## Beispiel Book Crossing-Datensatz

-   Analyse von Unterschieden in Buchbewertungen zwischen Altersgruppen

## Interpretation

-   F-Statistik und Varianzvergleich
-   Post-Hoc Tests zur Identifizierung spezifischer Gruppenunterschiede

# Sitzung 9: Korrelationsanalyse

## Was ist eine Korrelation?

-   Definition statistischer Zusammenhänge
-   Beispiele für korrelierte Daten

## Warum sind Korrelationen interessant?

-   Analyse historischer Daten
-   Ethische Einschränkungen bei Experimenten

## Vor der Korrelation kommt die Kovarianz

-   Berechnung und Bedeutung der Kovarianz
-   Standardisierung zur Korrelation

## Wichtige Aspekte der Korrelation

-   Keine implizierte Kausalrichtung
-   Scheinkorrelationen
-   Pearson's Korrelationskoeffizient und seine Interpretation
-   p-Wert bei Korrelationen

## Korrelations-Tests

-   Pearson-Korrelation: linear
-   Spearman-Korrelation: monoton, rangbasiert
-   Kendall-Tau-Korrelation: Rangordnungsübereinstimmung

## Unterschied Korrelation zu Regression

-   Korrelation misst Stärke des Zusammenhangs
-   Regression prognostiziert Werte

## Korrelation in R

-   Anwendung von `cor.test()` und Scatterplots
-   Kausalität vs. Korrelation

## Inter-Rater Reliability

-   Definition und Ziel der Inter-Rater Reliability
-   Konsistenz zwischen verschiedenen Beurteilern

## Methoden zur Messung der IRR

-   Cohen's Kappa: zwei Rater, kategoriale Daten
-   Fleiss' Kappa: mehr als zwei Rater, kategoriale Daten
-   Intraclass Correlation Coefficient (ICC): kontinuierliche Daten

## Interpretation von IRR-Maßen

-   Skalen für Cohen's Kappa, Fleiss' Kappa und ICC
-   Praktische Beispiele

# Sitzung 10: Einfache Lineare Regression

## Wofür brauche ich lineare Regression?

-   Anwendungsbeispiele: Fairer Preis für gebrauchte Artikel

## Lineare Regression

-   Vorhersagen mit Regressionslinien
-   `lm()`, `summary()`
-   `geom_smooth(method = "lm")`
-   Interpretation der Koeffizienten

## Heteroskedastizität beachten

-   Verteilung der Residuen um die Regressionslinie
-   Homoskedastizität vs. Heteroskedastizität

## Nicht-lineare Beziehungen

-   Umgang mit nicht-linearen Beziehungen
-   Transformationen zur Verbesserung der Modellpassung

## Logistische Regression

-   Vorhersage binärer abhängiger Variablen
-   Anwendungsbereiche: Medizin, Finanzen, Marketing

## Das logistische Regressionsmodell

-   Verwendung von `glm()` in R
-   Interpretation der Log-Odds
-   Modellbewertung mit Konfusionsmatrix und ROC-Kurve

# Sitzung 11: Chi-Quadrat-Test & kategoriale Daten

## Chi-Quadrat-Test

-   Kategoriale Daten analysieren
-   Häufigkeitstabellen, `chisq.test()`
-   Visualisierung: Balken, Mosaikplots

## Integration der gelernten Methoden

-   Zusammenführung aller Techniken
-   Fallstudie mit einem realen Datensatz
-   Von der Datenaufbereitung bis zur Interpretation

## Sitzung 12: Abschluss und Ausblick

## Zusammenfassung der wichtigsten Methoden

-   Deskriptive Statistik
-   Inferenzstatistik
-   Korrelation und Regression
-   Hypothesentests

## Überblick: Weiterführende statistische Methoden

-   ANOVA (Varianzanalyse)
-   Multiple Regression
-   Faktoranalyse
-   Zeitreihenanalyse
-   Bayesianische Statistik

## Offene Fragen und Diskussion

## Evaluation und Feedback

## Reguläre Ausdrücke

-   Mustererkennung in Daten
-   Anwendung in `filter()` und `mutate()`
